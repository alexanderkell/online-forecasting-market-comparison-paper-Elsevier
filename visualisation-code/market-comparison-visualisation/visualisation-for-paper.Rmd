---
title: "R Notebook"
output: html_notebook
---



```{r}
library("ggplot2")
library("dplyr")
library("plyr")
library(tidyr)
```


```{r}
normDataWithin <- function(data=NULL, idvar, measurevar, betweenvars=NULL,
                           na.rm=FALSE, .drop=TRUE) {
  library(plyr)
  
  # Measure var on left, idvar + between vars on right of formula.
  data.subjMean <- ddply(data, c(idvar, betweenvars), .drop=.drop,
                         .fun = function(xx, col, na.rm) {
                           c(subjMean = mean(xx[,col], na.rm=na.rm))
                         },
                         measurevar,
                         na.rm
  )
  
  # Put the subject means with original data
  data <- merge(data, data.subjMean)
  
  # Get the normalized data in a new column
  measureNormedVar <- paste(measurevar, "_norm", sep="")
  data[,measureNormedVar] <- data[,measurevar] - data[,"subjMean"] +
    mean(data[,measurevar], na.rm=na.rm)
  
  # Remove this subject mean column
  data$subjMean <- NULL
  
  return(data)
}

summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
  library(plyr)
  
  # New version of length which can handle NA's: if na.rm==T, don't count them
  length2 <- function (x, na.rm=FALSE) {
    if (na.rm) sum(!is.na(x))
    else       length(x)
  }
  
  # This does the summary. For each group's data frame, return a vector with
  # N, mean, and sd
  datac <- ddply(data, groupvars, .drop=.drop,
                 .fun = function(xx, col) {
                   c(N    = length2(xx[[col]], na.rm=na.rm),
                     mean = mean   (xx[[col]], na.rm=na.rm),
                     sd   = sd     (xx[[col]], na.rm=na.rm)
                   )
                 },
                 measurevar
  )
  
  # Rename the "mean" column    
  datac <- rename(datac, c("mean" = measurevar))
  
  datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
  
  # Confidence interval multiplier for standard error
  # Calculate t-statistic for confidence interval: 
  # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
  ciMult <- qt(conf.interval/2 + .5, datac$N-1)
  datac$ci <- datac$se * ciMult
  
  return(datac)
}

SummarySE <- function(data=NULL, measurevar, betweenvars=NULL, withinvars=NULL,
                           idvar=NULL, na.rm=FALSE, conf.interval=.95, .drop=TRUE) {
  
  # Ensure that the betweenvars and withinvars are factors
  factorvars <- vapply(data[, c(betweenvars, withinvars), drop=FALSE],
                       FUN=is.factor, FUN.VALUE=logical(1))
  
  if (!all(factorvars)) {
    nonfactorvars <- names(factorvars)[!factorvars]
    message("Automatically converting the following non-factors to factors: ",
            paste(nonfactorvars, collapse = ", "))
    data[nonfactorvars] <- lapply(data[nonfactorvars], factor)
  }
  
  # Get the means from the un-normed data
  datac <- summarySE(data, measurevar, groupvars=c(betweenvars, withinvars),
                     na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
  
  # Drop all the unused columns (these will be calculated with normed data)
  datac$sd <- NULL
  datac$se <- NULL
  datac$ci <- NULL
  
  # Norm each subject's data
  ndata <- normDataWithin(data, idvar, measurevar, betweenvars, na.rm, .drop=.drop)
  
  # This is the name of the new column
  measurevar_n <- paste(measurevar, "_norm", sep="")
  
  # Collapse the normed data - now we can treat between and within vars the same
  ndatac <- summarySE(ndata, measurevar_n, groupvars=c(betweenvars, withinvars),
                      na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
  
  # Apply correction from Morey (2008) to the standard error and confidence interval
  #  Get the product of the number of conditions of within-S variables
  nWithinGroups    <- prod(vapply(ndatac[,withinvars, drop=FALSE], FUN=nlevels,
                                  FUN.VALUE=numeric(1)))
  correctionFactor <- sqrt( nWithinGroups / (nWithinGroups-1) )
  
  # Apply the correction factor
  ndatac$sd <- ndatac$sd * correctionFactor
  ndatac$se <- ndatac$se * correctionFactor
  ndatac$ci <- ndatac$ci * correctionFactor
  
  # Combine the un-normed means with the normed results
  merge(datac, ndatac)
}
```



```{r}
offline_ml = read.csv('/Users/alexanderkell/Documents/PhD/Projects/10-ELECSIM/run/market_forecasting_comparison/data/results/results/demand_initial_exploration-2020-02-24 05:18:05.717624+00:00.csv')

ggplot(offline_ml) + geom_col(aes(x=estimator, y=-mean_test_neg_mean_absolute_error)) + xlab("Regressor Model") + ylab("Mean Absolute Error")  + coord_flip()
   #geom_errorbar(aes(xmin = (-mean_test_neg_mean_absolute_error - std_test_neg_mean_squared_error), xmax = (-mean_test_neg_mean_absolute_error + std_test_neg_mean_squared_error)))#+ coord_flip()  + theme(axis.text.x = element_text(angle = -90, hjust = 1))


offline_ml_long = reshape(offline_ml, direction="long", v.names="val", varying=list(c("split0_test_neg_mean_absolute_error","split1_test_neg_mean_absolute_error", 'split2_test_neg_mean_absolute_error', 'split3_test_neg_mean_absolute_error','split4_test_neg_mean_absolute_error')))



dfwc <- read.csv('offline_ml_long_sd.csv')

library(RColorBrewer)
my_blue = brewer.pal(n = 11, "Blues")[c(TRUE, FALSE)]
my_blue_nth = my_blue[-1]


offline_mae_plot = ggplot(dfwc, aes(x=estimator, y=-val, group=1)) +
  geom_col(fill="lightblue") +
  geom_errorbar(width=.1, aes(ymax=-val-ci, ymin=-val+ci)) + xlab("Regressor Model") + ylab("Mean Absolute Error")  + coord_flip() + theme_classic() + scale_colour_manual(values=my_blue_nth)+ theme(text = element_text(size=25), plot.margin=grid::unit(c(0,0,0,0), "mm"))



ggsave("plots/offline_mae_plot.eps", offline_mae_plot, dpi=1000, width = 30, height = 20, units = "cm")

```



```{r}
RandomForest_day = read.csv('/Users/alexanderkell/Documents/PhD/Projects/10-ELECSIM/run/market_forecasting_comparison/data/results/results/RandomForestRegressor_actual_vs_predicted.csv')

RandomForest_day$variable = gsub('predictions', 'Predictions', RandomForest_day$variable)
RandomForest_day$variable = gsub('actuals', 'Actuals', RandomForest_day$variable)


# randomforest_plot = ggplot(data=RandomForest_day) + geom_line(aes(x=index, y=value, colour=variable),size=3) + xlab("Hour of Day") + ylab("Demand (MW)")+ theme_classic() + theme(text = element_text(size=40), plot.margin=grid::unit(c(0,0,0,0), "mm"))

# ggsave("plots/best_offline_learning_day_simulation.eps", randomforest_plot, dpi=1000, width = 30, height = 20, units = "cm")

```


```{r}
offline_rf_actual_predicted = read.csv('/Users/alexanderkell/Documents/PhD/Projects/10-ELECSIM/run/market_forecasting_comparison/data/results/results/RandomForestRegressor_actual_vs_predicted.csv')
offline_rf_actual_predicted
offline_rf_pred_actuals_plot = ggplot(offline_rf_actual_predicted) + geom_line(aes(x=hour, colour=variable, y=value), size=2) + theme_classic() + coord_cartesian(clip = 'off') + theme(text = element_text(size=40), legend.position = "bottom", plot.margin=grid::unit(c(0,0,0,0), "mm")) + ylab("Demand (MW)") + xlab("Hour of Week") +
  scale_y_continuous(expand = c(0.1,0.1))
print(offline_rf_pred_actuals_plot)
ggsave("plots/offline_rf_actual_predicted.eps", offline_rf_pred_actuals_plot, dpi=1000, width = 40, height = 20, units = "cm")
```

```{r}
offline_rf_actual_predicted = read.csv('/Users/alexanderkell/Documents/PhD/Projects/10-ELECSIM/run/market_forecasting_comparison/data/results/results/RandomForestRegressor_actual_vs_predicted.csv')
online_bc_actual_predicted = read.csv('/Users/alexanderkell/Documents/PhD/Projects/10-ELECSIM/run/market_forecasting_comparison/data/results/results/boxcoxonline_actual_vs_predicted.csv')


offline_rf_actual_predicted

# offline_rf_pred_actuals_plot = ggplot(offline_rf_actual_predicted) + geom_line(aes(x=hour, colour=variable, y=value))+ geom_line(data=online_bc_actual_predicted, aes(x=hour, colour=variable, y=value), color="blue") + theme_classic() + coord_cartesian(clip = 'off') + theme(text = element_text(size=40), legend.position = "bottom", plot.margin=grid::unit(c(0,0,0,0), "mm")) + ylab("Demand (MW)") + xlab("Hour of Week") +
  scale_y_continuous(expand = c(0.1,0.1))
print(offline_rf_pred_actuals_plot)
ggsave("plots/offline_rf_actual_predicted.eps", offline_rf_pred_actuals_plot, dpi=1000, width = 40, height = 20, units = "cm")

library(reshape2)
# dcast(offline_rf_actual_predicted, value ~ hour+variable)
offline_rf_actual_predicted_wide = reshape(offline_rf_actual_predicted, idvar = "hour", timevar = "variable", direction = "wide")

offline_rf_actual_predicted_wide = select(offline_rf_actual_predicted_wide, -X.predictions, -X.actuals)


offline_rf_actual_predicted_wide = reshape(offline_rf_actual_predicted, idvar = "hour", timevar = "variable", direction = "wide") %>% select(-X.predictions, -X.actuals) %>% rename(c("value.actuals"="rf_actual", 'value.predictions'="Extra Trees"))


online_bc_actual_predicted_wide = reshape(online_bc_actual_predicted, idvar = "hour", timevar = "variable", direction = "wide") %>% select(-X.predictions, -X.actuals) %>% rename(c("value.actuals"="Actuals", 'value.predictions'="Box-Cox"))
                                                                                                                                                                                  
                                                                                                                            both_long = cbind(online_bc_actual_predicted_wide, select(offline_rf_actual_predicted_wide, `Extra Trees`)) %>% melt(id.vars='hour', measure.vars=c('Actuals', 'Box-Cox', 'Extra Trees'))

                                                                                                                            both_pred_actuals_plot = ggplot(both_long) + geom_line(aes(x=hour, colour=variable, y=value), size=2) + theme_classic() + coord_cartesian(clip = 'off') + theme(text = element_text(size=40), plot.margin=grid::unit(c(0,0,0,0), "mm")) + ylab("Demand (MW)") + xlab("Hour of Week") +
  scale_y_continuous(expand = c(0.1,0.1))
print(both_pred_actuals_plot)
ggsave("plots/both_actual_predicted.eps", both_pred_actuals_plot, dpi=1000, width = 40, height = 20, units = "cm")


```


```{r}
offline_results = read.csv('/Users/alexanderkell/Documents/PhD/Projects/10-ELECSIM/run/market_forecasting_comparison/data/results/results/demand_initial_exploration-2020-02-24 05:18:05.717624+00:00.csv')

head(offline_results)

```
```{r}
offline_results$mean_test_mean_absolute_error = abs(offline_results$mean_test_neg_mean_absolute_error)
offline_results$upper_mean_test_mean_absolute_error = offline_results$mean_test_mean_absolute_error + offline_results$std_test_neg_mean_absolute_error
offline_results$lower_mean_test_mean_absolute_error = offline_results$mean_test_mean_absolute_error - offline_results$std_test_neg_mean_absolute_error

offline_results$lower_mean_fit_time = offline_results$mean_fit_time - offline_results$std_fit_time
offline_results$upper_mean_fit_time = offline_results$mean_fit_time + offline_results$std_fit_time

p = ggplot(data = offline_results, aes(x=mean_test_mean_absolute_error, y=mean_fit_time, colour=estimator)) + geom_point(size=3.5) + geom_errorbarh(aes(xmin=upper_mean_test_mean_absolute_error, xmax=lower_mean_test_mean_absolute_error), width=0.2) + geom_errorbar(aes(ymax=upper_mean_fit_time, ymin=lower_mean_fit_time))+ theme(text = element_text(size=20), legend.position = "bottom", plot.margin=grid::unit(c(0,0,0,0), "mm")) + ylab("Fit Time (S)") + xlab("Mean Absolute Error (MAE)")+ theme_classic() 

print(p)
ggsave("plots/offline_fit_time_vs_mae.eps", p)
```
```{r}
offline_results = read.csv('/Users/alexanderkell/Documents/PhD/Projects/10-ELECSIM/run/market_forecasting_comparison/data/results/results/demand_initial_exploration-2020-02-24 05:18:05.717624+00:00.csv')
head(offline_results)
```
```{r}
offline_results$mean_test_mean_absolute_error = abs(offline_results$mean_test_neg_mean_absolute_error)
offline_results$upper_mean_test_mean_absolute_error = offline_results$mean_test_mean_absolute_error + offline_results$std_test_neg_mean_absolute_error
offline_results$lower_mean_test_mean_absolute_error = offline_results$mean_test_mean_absolute_error - offline_results$std_test_neg_mean_absolute_error
offline_results$lower_mean_fit_time = offline_results$mean_fit_time - offline_results$std_fit_time
offline_results$upper_mean_fit_time = offline_results$mean_fit_time + offline_results$std_fit_time
p = ggplot(data = offline_results, aes(x=mean_test_mean_absolute_error, y=mean_fit_time, colour=estimator)) + geom_point(size=3.5) + geom_errorbarh(aes(xmin=upper_mean_test_mean_absolute_error, xmax=lower_mean_test_mean_absolute_error), width=0.2) + geom_errorbar(aes(ymax=upper_mean_fit_time, ymin=lower_mean_fit_time))+ theme(text = element_text(size=20), legend.position = "bottom", plot.margin=grid::unit(c(0,0,0,0), "mm")) + ylab("Fit Time (S)") + xlab("Mean Absolute Error (MAE)")+ theme_classic() 
ggsave("plots/offline_fit_time_vs_mae.eps", p)
```





```{r}

```





```{r new results}

new_offline_results = read.csv("/Users/alexanderkell/Documents/PhD/Projects/10-ELECSIM/run/market_forecasting_comparison/run/ML/demand_initial_exploration-2020-06-11 07:35:51.853816+01:00.csv")

new_offline_results$mean_test_mean_absolute_error = abs(new_offline_results$mean_score_time)
new_offline_results$upper_mean_test_mean_absolute_error = new_offline_results$mean_test_mean_absolute_error + new_offline_results$std_test_neg_mean_absolute_error
new_offline_results$lower_mean_test_mean_absolute_error = new_offline_results$mean_test_mean_absolute_error - new_offline_results$std_test_neg_mean_absolute_error
new_offline_results$lower_mean_fit_time = new_offline_results$mean_fit_time - new_offline_results$std_fit_time
new_offline_results$upper_mean_fit_time = new_offline_results$mean_fit_time + new_offline_results$std_fit_time



ggplot(data = new_offline_results, aes(x=mean_test_mean_absolute_error, y=mean_fit_time, colour=estimator)) + geom_point(size=3.5) + geom_errorbarh(aes(xmin=upper_mean_test_mean_absolute_error, xmax=lower_mean_test_mean_absolute_error), width=0.2) + geom_errorbar(aes(ymax=upper_mean_fit_time, ymin=lower_mean_fit_time))+ theme(text = element_text(size=20), legend.position = "bottom", plot.margin=grid::unit(c(0,0,0,0), "mm")) + ylab("Fit Time (S)") + xlab("Mean Absolute Error (MAE)")+ theme_classic() 

```


```{r}

offline_results_long = read.csv('/Users/alexanderkell/Documents/PhD/Projects/10-ELECSIM/run/market_forecasting_comparison/notebooks/data/offline_models_results_long.csv')

offline_results_long$mean_test_mean_absolute_error = abs(offline_results_long$mean_test_score)
offline_results_long$upper_mean_test_mean_absolute_error = offline_results_long$mean_test_mean_absolute_error + offline_results_long$std_score_time
offline_results_long$lower_mean_test_mean_absolute_error = offline_results_long$mean_test_mean_absolute_error - offline_results_long$std_score_time
offline_results_long$lower_mean_fit_time = offline_results_long$mean_fit_time - offline_results_long$std_fit_time
offline_results_long$upper_mean_fit_time = offline_results_long$mean_fit_time + offline_results_long$std_fit_time

opacity = 0.1

p = ggplot(data = offline_results_long, aes(x=mean_test_mean_absolute_error, y=mean_fit_time, colour=estimator)) + geom_point(size=2, alpha=0.6) + geom_errorbarh(aes(xmin=upper_mean_test_mean_absolute_error, xmax=lower_mean_test_mean_absolute_error), alpha=opacity) + geom_errorbar(aes(ymax=upper_mean_fit_time, ymin=lower_mean_fit_time), alpha=opacity)+ theme(text = element_text(size=20), legend.position = "bottom", plot.margin=grid::unit(c(0,0,0,0), "mm")) + ylab("Fit Time (S)") + xlab("Mean Absolute Error (MAE)")+ theme_classic()  + scale_x_continuous(trans='log10') + scale_y_continuous(trans='log10')

ggsave("plots/offline_fit_time_vs_mae_all_results_opaque.eps", p)

```



